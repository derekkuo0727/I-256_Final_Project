{
 "metadata": {
  "name": "Prediction_Main_new"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** Tool function: get_line_num_by_key(key) ***\n",
      "Input: a keyword\n",
      "Output: a list of line numbers that each of the line contains the keyword."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_line_num_by_key(key):\n",
      "    line_num = []\n",
      "    for i in range(len(keyword_list)):\n",
      "        if key in keyword_list[i].split(\" \"):\n",
      "            line_num.append(i)\n",
      "    return line_num"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** Tool function: data_cleaner(raw_text) ***\n",
      "Input: a raw text directly extracted from question_lists or title_lists\n",
      "Ouput: a list of words (ready to use) which formats have been removed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def data_cleaner(raw_text):\n",
      "    text = re.sub(\"<p>|</p>|<pre>|<code>|</pre>|</code>\", '', raw_text)\n",
      "    text = re.sub(\"\\n|[,!;?:/']\", ' ', text)\n",
      "    text = text.split(\" \")\n",
      "    li = []\n",
      "    for w in text:\n",
      "        w = w.lower()\n",
      "        if w != \"\":\n",
      "            if w[-1] == \".\":\n",
      "                w = w[:-1]\n",
      "            li.append(w)\n",
      "    return li\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** Tool function: code_extractor(raw_text) ***\n",
      "Input: a raw text directly extracted from question_lists or title_lists\n",
      "Output: a list of code sections "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def code_extractor(raw_text):\n",
      "    m = re.findall('<pre><code>(.+?)</code></pre>', raw_text, re.S)\n",
      "    return m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 0. Create a small train set (small_train.csv) from train.csv ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "input_file = open(\"train.csv\",'r')\n",
      "output_file = open(\"small_train.csv\",\"w\")\n",
      "reader = csv.reader( input_file )\n",
      "\n",
      "i = 0\n",
      "\n",
      "for line in reader:\n",
      "    a = csv.writer(output_file, delimiter=',')\n",
      "    a.writerow(line)\n",
      "    i += 1\n",
      "    if i > 1000005:\n",
      "        break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 0.1 Variable Definition ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TRAINING_LINE_NUMBER = 100000\n",
      "TOP_KEYWORDS = 50\n",
      "TOP_WORDS = 200"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 1. Load small_train.csv into title, question, keyword list ***\n",
      "variable: ___ of lines to load"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import nltk\n",
      "\n",
      "skip_first_line = True\n",
      "\n",
      "input_file = open(\"small_train.csv\",'r')\n",
      "reader = csv.reader( input_file )\n",
      "if skip_first_line:\n",
      "    reader.next()\n",
      "\n",
      "#id_list = []\n",
      "title_list = []\n",
      "question_list = []\n",
      "keyword_list = []\n",
      "\n",
      "i = 0\n",
      "\n",
      "for line in reader:\n",
      "#    id_list.append(line[0])\n",
      "    title_list.append(line[1])\n",
      "    question_list.append(line[2])\n",
      "    keyword_list.append(line[3])\n",
      "    i+=1\n",
      "    if i == TRAINING_LINE_NUMBER:\n",
      "        break\n",
      "# Now you can just call the function:\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 2. Build-up freqency table to find the most frequent keywords ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fq = nltk.FreqDist([keyword for keywords in keyword_list for keyword in keywords.split(\" \")])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 2.1 Checking_point: print the top x keywords and their frquency ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(TOP_KEYWORDS):\n",
      "    key = fq.keys()[i]\n",
      "    print key, fq[key]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "c# 7786\n",
        "java 6788\n",
        "php 6575\n",
        "javascript 6135\n",
        "android 5317\n",
        "jquery 4949\n",
        "c++ 3278\n",
        "python 3082\n",
        "iphone"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3050\n",
        "asp.net 2937\n",
        "mysql 2837\n",
        "html 2720\n",
        ".net 2685\n",
        "ios 2263\n",
        "sql 2243\n",
        "objective-c 2234\n",
        "css 2118\n",
        "linux"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2088\n",
        "ruby-on-rails 1951\n",
        "c 1620\n",
        "windows 1583\n",
        "sql-server 1268\n",
        "ruby 1173\n",
        "wpf 1105\n",
        "xml 1055\n",
        "ajax 1000\n",
        "database"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 994\n",
        "regex 983\n",
        "windows-7 982\n",
        "asp.net-mvc 938\n",
        "osx 884\n",
        "django"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 838\n",
        "xcode 827\n",
        "arrays 822\n",
        "vb.net 781\n",
        "facebook 768\n",
        "eclipse 737\n",
        "ubuntu 691\n",
        "performance 682\n",
        "ruby-on-rails-3 681\n",
        "json"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 675\n",
        "networking 629\n",
        "multithreading 601\n",
        "string 592\n",
        "visual-studio-2010 581\n",
        "winforms 576\n",
        "asp.net-mvc-3 548\n",
        "security"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 547\n",
        "wcf 546\n",
        "wordpress 545\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 3. Build the freq_word[keyword] dictionary (unigram version) ***\n",
      "Variable: top __ keyword\n",
      "Variable: top __ words in a keyword\n",
      "\n",
      "keyword: one of the top x keywords \n",
      "freq_word[keyword]: return a dictionary of {word: [tf, idf]}\n",
      "ex. freq_word['java'] ==> {\"data\": [123,234],\"class\": [23,32],...}\n",
      "    which means 'data' has appeared 123 times inside keyword and 234 times outside keyword"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#unigram\n",
      "import re\n",
      "\n",
      "import pickle\n",
      "tagger = pickle.load(open(\"treebank_brill_aubt.pickle\"))\n",
      "\n",
      "from nltk.corpus import stopwords \n",
      "\n",
      "freq_word = {}\n",
      "\n",
      "# build tf\n",
      "for keyword in fq.keys()[:TOP_KEYWORDS]:\n",
      "    line_num = get_line_num_by_key(keyword)\n",
      "    target_words = []\n",
      "    for num in line_num:\n",
      "        text = data_cleaner(question_list[num])\n",
      "        text = tagger.tag(text)\n",
      "        for (word,tag) in text:\n",
      "            if (not word in stopwords.words('english'))and tag in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"] and word not in [\"\",\"=\",\"{\",\"}\",\"(\",\")\",\"+\",\"==\"]:\n",
      "                    target_words.append(word.lower())\n",
      "    fdist = nltk.FreqDist(target_words)    \n",
      "    key_value = {}\n",
      "    for key in fdist.keys()[:TOP_WORDS]:\n",
      "        key_value[key] = [fdist[key],0]\n",
      "    freq_word[keyword] = key_value\n",
      "\n",
      "# build idf    \n",
      "for i in range(TRAINING_LINE_NUMBER):\n",
      "    keywords = keyword_list[i].split(\" \")\n",
      "    text = data_cleaner(question_list[i])\n",
      "    for keyword in freq_word.keys():\n",
      "        if keyword not in keywords:\n",
      "            for word in text:\n",
      "                if word in freq_word[keyword].keys():\n",
      "                    freq_word[keyword][word][1] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freq_word[\"c#\"]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "{'\"': [19, 290],\n",
        " '\"&lt': [15, 42],\n",
        " '\"+': [14, 1],\n",
        " '&gt': [26, 400],\n",
        " '&lt': [131, 1641],\n",
        " '<': [22, 286],\n",
        " '<a': [14, 235],\n",
        " '=&gt': [24, 178],\n",
        " 'a>': [14, 222],\n",
        " 'c#': [18, 11],\n",
        " 'class': [25, 165],\n",
        " 'code': [34, 343],\n",
        " 'comment&gt': [16, 1],\n",
        " 'data': [29, 181],\n",
        " 'm': [33, 402],\n",
        " 'method': [24, 132],\n",
        " 'new': [82, 330],\n",
        " 'object': [15, 128],\n",
        " 'public': [53, 218],\n",
        " 'return': [24, 192],\n",
        " 'static': [17, 62],\n",
        " 'strong>': [16, 196],\n",
        " 'thanks': [19, 172],\n",
        " 'type': [17, 104],\n",
        " 'user': [33, 188],\n",
        " 'value': [16, 131],\n",
        " 've': [16, 172],\n",
        " 'void': [21, 83],\n",
        " 'way': [25, 220],\n",
        " 'xml': [18, 80]}"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** TODO: 3.2 Build the freq_word[keyword] dictionary (bigram version) ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bigrams\n",
      "\"\"\"\n",
      "import re\n",
      "import pickle\n",
      "tagger = pickle.load(open(\"treebank_brill_aubt.pickle\"))\n",
      "\n",
      "from nltk import bigrams\n",
      "\n",
      "freq_word = {}\n",
      "for keyword in fq.keys()[:10]:\n",
      "    line_num = get_line_num_by_key(keyword)\n",
      "    fdist = nltk.FreqDist()\n",
      "    for num in line_num:\n",
      "        text = title_list[num]\n",
      "        text = re.sub('[,.!;()?:/]', ' ', text)\n",
      "        text = text.split(\" \")\n",
      "        text = tagger.tag(text)\n",
      "        text = bigrams(text)\n",
      "        \n",
      "        for (word1,tag1),(word2,tag2) in text:\n",
      "            if (tag1 in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"] or tag2 in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"]) and (word1 != \"\") and (word2 != \"\"):\n",
      "                fdist.inc(word1.lower()+ \" \" + word2.lower())\n",
      "    key_value = []\n",
      "    for key in fdist.keys()[:200]:\n",
      "        key_value.append((key,fdist[key]))\n",
      "    freq_word[keyword] = key_value\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 5. Ouput the TFIDF table to file ***\n",
      "Each line contains [keyword, word, tf/idf, tf, appear times in other keyword, idf, total frequency of keywords]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "from __future__ import division\n",
      "f = open(\"tfidf\",\"w\")\n",
      "\n",
      "for keyword in fq.keys()[:TOP_KEYWORDS]:\n",
      "    for word in freq_word[keyword].keys():\n",
      "        tf = freq_word[keyword][word][0]\n",
      "        idf = freq_word[keyword][word][1]\n",
      "        f.write(str(keyword) + \"\\t\" + str(word) + \"\\t\" + str(tf/(idf+1)) + \"\\t\" + str(tf) + \"\\t\" + str(idf) + \"\\t\" +str(fq[keyword])+ \"\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 6.0 Evaluation Variable Definition **"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TFIDF_Threshold = 10\n",
      "NUMBER_OF_MATCHES = 2\n",
      "TESTING_LINES = 100,200"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 6. Evaluation: Load the tfidf table to build up score table ***\n",
      "variable: load only the entries that td/idf score over __ score\n",
      "variable: specify which tfidf table want to load\n",
      "\n",
      "score_table is a word based dictionary that give a word as key return a list of keywords that has tfidf over __ score with the word\n",
      "\n",
      "ex. score_table[\"class\"] ==> [\"java\",\"c#\",\"c++\",...]\n",
      "\n",
      "means the word \"class\" has strong relationship (tfidf > __) with following keywords: java, c#, c++\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score_file = open(\"tfidf\",\"r\")\n",
      "\n",
      "score_table = {}\n",
      "\n",
      "for line in score_file:\n",
      "    line = line.strip(\"\\n\")\n",
      "    line = line.split(\"\\t\")\n",
      "    if float(line[2]) > TFIDF_Threshold: \n",
      "        if line[1] not in score_table:\n",
      "            score_table[line[1]] = [line[0]]\n",
      "        else:\n",
      "            score_table[line[1]].append(line[0])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 7. Evaluation: output the prediction keywords and compare with the correct keywords ***\n",
      "variable: # of lines to predict\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Unigram\n",
      "prediction_table = []\n",
      "for i in range(len(title_list)):\n",
      "    text = data_cleaner(question_list[i])\n",
      "    key_word = {}\n",
      "    prediction = []\n",
      "    for word in text:\n",
      "        if word in score_table:\n",
      "            for j in range(len(score_table[word])):\n",
      "                if score_table[word][j] not in key_word:\n",
      "                    key_word[score_table[word][j]] = 1\n",
      "                else:\n",
      "                    key_word[score_table[word][j]] += 1\n",
      "    for key in key_word.keys():\n",
      "        if key_word[key] > NUMBER_OF_MATCHES:\n",
      "            prediction.append(key)\n",
      "    prediction_table.append(prediction)\n",
      "\n",
      "for i in range(TESTING_LINES):\n",
      "    print \"line:\", i\n",
      "    print prediction_table[i]\n",
      "    print keyword_list[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 8. Evaluation tool: function accuracy_query(keyword) ***\n",
      "input: a keyword\n",
      "return: print the precision information about the keyword\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "def accuracy_query(keyword):\n",
      "    correct_guess = 0\n",
      "    total_key = 0\n",
      "    total_guess = 0\n",
      "    for i in range(TESTING_LINES):\n",
      "        for guess in prediction_table[i]:\n",
      "            if guess == keyword:\n",
      "                total_guess +=1\n",
      "                if guess in keyword_list[i]:\n",
      "                    correct_guess +=1\n",
      "        for key in keyword_list[i].split(\" \"):\n",
      "            if key == keyword:\n",
      "                total_key +=1\n",
      "    print \"Total key is:\", total_key\n",
      "    print \"Total guess is:\", total_guess\n",
      "    print \"Correct guess is:\", correct_guess\n",
      "    print \"Recall is:\", correct_guess/total_key\n",
      "    print \"Accuracy is:\", correct_guess/total_guess\n",
      "    print \"Recall is:\", 2*(correct_guess/total_key)*(correct_guess/total_guess)/(correct_guess/total_key+correct_guess/total_guess)\n",
      "    \n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 9. Test specific keyword accuracy ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy_query(\"r\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}