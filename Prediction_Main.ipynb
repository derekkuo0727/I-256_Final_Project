{
 "metadata": {
  "name": "Prediction_Main"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** Tool function: get_line_num_by_key(key) ***\n",
      "Input: a keyword\n",
      "Output: a list of line numbers that each of the line contains the keyword."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_line_num_by_key(key):\n",
      "    line_num = []\n",
      "    for i in range(len(keyword_list)):\n",
      "        if key in keyword_list[i].split(\" \"):\n",
      "            line_num.append(i)\n",
      "    return line_num"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** Tool function: data_cleaner(raw_text) ***\n",
      "Input: a raw text directly extracted from question_lists or title_lists\n",
      "Ouput: a list of words (ready to use) which formats have been removed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def data_cleaner(raw_text):\n",
      "    text = re.sub(\"<p>|</p>|<pre>|<code>|</pre>|</code>\", '', raw_text)\n",
      "    text = re.sub(\"\\n|[,!;?:/']\", ' ', text)\n",
      "    text = text.split(\" \")\n",
      "    li = []\n",
      "    for w in text:\n",
      "        w = w.lower()\n",
      "        if w != \"\":\n",
      "            if w[-1] == \".\":\n",
      "                w = w[:-1]\n",
      "            li.append(w)\n",
      "    return li\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** Tool function: code_extractor(raw_text) ***\n",
      "Input: a raw text directly extracted from question_lists or title_lists\n",
      "Output: a list of code sections "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def code_extractor(raw_text):\n",
      "    m = re.findall('<pre><code>(.+?)</code></pre>', raw_text, re.S)\n",
      "    return m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 0. Create a small train set (small_train.csv) from train.csv ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "input_file = open(\"train.csv\",'r')\n",
      "output_file = open(\"small_train.csv\",\"w\")\n",
      "reader = csv.reader( input_file )\n",
      "\n",
      "i = 0\n",
      "\n",
      "for line in reader:\n",
      "    a = csv.writer(output_file, delimiter=',')\n",
      "    a.writerow(line)\n",
      "    i += 1\n",
      "    if i > 1000005:\n",
      "        break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 1. Load small_train.csv into title, question, keyword list ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import nltk\n",
      "\n",
      "skip_first_line = True\n",
      "\n",
      "input_file = open(\"small_train.csv\",'r')\n",
      "reader = csv.reader( input_file )\n",
      "if skip_first_line:\n",
      "    reader.next()\n",
      "\n",
      "#id_list = []\n",
      "title_list = []\n",
      "question_list = []\n",
      "keyword_list = []\n",
      "\n",
      "i = 0\n",
      "\n",
      "for line in reader:\n",
      "#    id_list.append(line[0])\n",
      "    title_list.append(line[1])\n",
      "    question_list.append(line[2])\n",
      "    keyword_list.append(line[3])\n",
      "    i+=1\n",
      "    if i == 300000:\n",
      "        break\n",
      "# Now you can just call the function:\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 308
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 2. Build-up freqency table to find the most frequent keywords ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fq = nltk.FreqDist([keyword for keywords in keyword_list for keyword in keywords.split(\" \")])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 309
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 2.1 Checking_point: print the top x keywords and their frquency ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(200):\n",
      "    key = fq.keys()[i]\n",
      "    print key, fq[key]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "c# 23141\n",
        "java 20479\n",
        "php 19525\n",
        "javascript 18209\n",
        "android 15957\n",
        "jquery 14872\n",
        "c++"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9949\n",
        "python 9329\n",
        "iphone 9141\n",
        "asp.net 8791\n",
        "mysql 8526\n",
        "html 8243\n",
        ".net"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8081\n",
        "ios 6895\n",
        "objective-c 6764\n",
        "sql 6593\n",
        "css 6487\n",
        "linux 6350\n",
        "ruby-on-rails"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5798\n",
        "windows 4888\n",
        "c 4751\n",
        "sql-server 3757\n",
        "ruby 3587\n",
        "wpf 3260\n",
        "xml"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3189\n",
        "windows-7 2982\n",
        "database 2981\n",
        "ajax 2966\n",
        "asp.net-mvc 2882\n",
        "regex 2873\n",
        "osx"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2623\n",
        "xcode 2581\n",
        "arrays 2534\n",
        "django 2534\n",
        "vb.net 2280\n",
        "eclipse"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2234\n",
        "facebook 2161\n",
        "json 2157\n",
        "ruby-on-rails-3 2156\n",
        "ubuntu 2114\n",
        "performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2000\n",
        "multithreading 1905\n",
        "networking 1862\n",
        "winforms 1839\n",
        "string 1825\n",
        "asp.net-mvc-3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1760\n",
        "visual-studio-2010 1746\n",
        "security 1685\n",
        "bash 1607\n",
        "wcf 1603\n",
        "homework"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1582\n",
        "image 1576\n",
        "html5 1572\n",
        "wordpress 1553\n",
        "visual-studio 1518\n",
        "forms"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1516\n",
        "web-services 1505\n",
        "sql-server-2008 1477\n",
        "oracle 1468\n",
        "algorithm 1464\n",
        "linq 1464\n",
        "perl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1448\n",
        "git 1446\n",
        "actionscript-3 1400\n",
        "email 1390\n",
        "query 1386\n",
        "silverlight 1354\n",
        "ipad"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1350\n",
        "cocoa 1343\n",
        "flash 1338\n",
        "apache 1335\n",
        "apache2 1332\n",
        "spring"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1327\n",
        "r 1305\n",
        "hibernate 1277\n",
        "cocoa-touch 1269\n",
        "swing 1241\n",
        "entity-framework"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1221\n",
        "excel 1206\n",
        "file 1174\n",
        "api 1130\n",
        "flex 1124\n",
        "shell 1105\n",
        "sqlite"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1099\n",
        "list 1078\n",
        "jquery-ui 1065\n",
        "tsql 1055\n",
        "internet-explorer 1042\n",
        "windows-xp 1033\n",
        "delphi"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1032\n",
        "firefox 1023\n",
        "qt 1013\n",
        ".htaccess 1009\n",
        "node.js 1004\n",
        "debugging"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000\n",
        "unix 989\n",
        "google-chrome 986\n",
        "svn 966\n",
        "postgresql 947\n",
        "http 945\n",
        "unit-testing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 944\n",
        "iis 932\n",
        "google-app-engine 926\n",
        "ssh 920\n",
        "sql-server-2005 913\n",
        "windows-phone-7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 906\n",
        "class 904\n",
        "oop 901\n",
        "codeigniter 900\n",
        "command-line 896\n",
        "matlab 890\n",
        "sockets"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 888\n",
        "validation 887\n",
        "memory 853\n",
        "function 852\n",
        "parsing 842\n",
        "jsp"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 820\n",
        "windows-server-2008 815\n",
        "authentication 805\n",
        "calculus 802\n",
        "magento 800\n",
        "events"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 795\n",
        "uitableview 795\n",
        "winapi 793\n",
        "tomcat 791\n",
        "google-maps 788\n",
        "design-patterns"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 787\n",
        "audio 786\n",
        "xaml 786\n",
        "templates 785\n",
        "mongodb"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 784\n",
        "search 780\n",
        "android-layout 777\n",
        "zend-framework 776\n",
        "plugins 775\n",
        "design"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 768\n",
        "visual-studio-2008 762\n",
        "pdf 760\n",
        "mvc 759\n",
        "real-analysis 759\n",
        "scala 758\n",
        "jquery-ajax"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 755\n",
        "sharepoint 750\n",
        "optimization 749\n",
        "google 742\n",
        "rest 742\n",
        "url"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 739\n",
        "facebook-graph-api 732\n",
        "session 732\n",
        "nhibernate 729\n",
        "linear-algebra 722\n",
        "dns 720\n",
        "table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 718\n",
        "video 716\n",
        "vim 708\n",
        "logging 703\n",
        "cakephp 701\n",
        "gwt 701\n",
        "jsf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 699\n",
        "permissions 697\n",
        "sorting 697\n",
        "ssl 695\n",
        "c#-4.0 692\n",
        "variables 689\n",
        "visual-c++"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 689\n",
        "date 683\n",
        "css3 670\n",
        "exception 669\n",
        "java-ee 669\n",
        "centos 664\n",
        "gui"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 664\n",
        "vba 664\n",
        "caching 663\n",
        "powershell 659\n",
        "web-applications 657\n",
        "drupal"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 643\n",
        "math 642\n",
        "maven 642\n",
        "browser 639\n",
        "listview 639\n",
        "probability 636\n",
        "object"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 630\n",
        "debian 626\n",
        "ms-access 623\n",
        "testing 620\n",
        "xslt 617\n",
        "mod-rewrite 616\n",
        "servlets"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 616\n",
        "dom 615\n",
        "generics 615\n",
        "active-directory 613\n",
        "redirect 604\n",
        "ios5 600\n",
        "datetime"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 599\n",
        "haskell 590\n",
        "database-design 582\n",
        "windows-server-2003 582\n",
        "core-data 576\n",
        "inheritance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 576\n",
        "opengl 575\n"
       ]
      }
     ],
     "prompt_number": 310
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 311
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 3. Build the freq_word[keyword] dictionary (unigram version) ***\n",
      "Variable: top __ keyword\n",
      "Variable: top __ words in a keyword\n",
      "\n",
      "keyword: one of the top x keywords \n",
      "freq_word[keyword]: return a list of (word, word_count) tuples\n",
      "ex. freq_word['java'] ==> [('jsp',200),('js',100),...]\n",
      "    which means 'jsp' has appeared 200 times in the questions that contain keyword 'java' "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#unigram\n",
      "import re\n",
      "\n",
      "import pickle\n",
      "tagger = pickle.load(open(\"treebank_brill_aubt.pickle\"))\n",
      "\n",
      "from nltk.corpus import stopwords \n",
      "\n",
      "freq_word = {}\n",
      "for keyword in fq.keys()[:200]:\n",
      "    line_num = get_line_num_by_key(keyword)\n",
      "    target_words = []\n",
      "    for num in line_num:\n",
      "        text = data_cleaner(question_list[num])\n",
      "        text = tagger.tag(text)\n",
      "        for (word,tag) in text:\n",
      "            if (not word in stopwords.words('english'))and tag in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"] and word not in [\"\",\"=\",\"{\",\"}\",\"(\",\")\",\"+\",\"==\"]:\n",
      "                    target_words.append(word.lower())\n",
      "    fdist = nltk.FreqDist(target_words)    \n",
      "    key_value = []\n",
      "    for key in fdist.keys()[:1000]:\n",
      "        key_value.append((key,fdist[key]))\n",
      "    freq_word[keyword] = key_value\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** TODO: 3.1 Build the freq_word[keyword] dictionary (bigram version) ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bigrams\n",
      "\"\"\"\n",
      "import re\n",
      "import pickle\n",
      "tagger = pickle.load(open(\"treebank_brill_aubt.pickle\"))\n",
      "\n",
      "from nltk import bigrams\n",
      "\n",
      "freq_word = {}\n",
      "for keyword in fq.keys()[:10]:\n",
      "    line_num = get_line_num_by_key(keyword)\n",
      "    fdist = nltk.FreqDist()\n",
      "    for num in line_num:\n",
      "        text = title_list[num]\n",
      "        text = re.sub('[,.!;()?:/]', ' ', text)\n",
      "        text = text.split(\" \")\n",
      "        text = tagger.tag(text)\n",
      "        text = bigrams(text)\n",
      "        \n",
      "        for (word1,tag1),(word2,tag2) in text:\n",
      "            if (tag1 in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"] or tag2 in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"]) and (word1 != \"\") and (word2 != \"\"):\n",
      "                fdist.inc(word1.lower()+ \" \" + word2.lower())\n",
      "    key_value = []\n",
      "    for key in fdist.keys()[:200]:\n",
      "        key_value.append((key,fdist[key]))\n",
      "    freq_word[keyword] = key_value\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 231,
       "text": [
        "'\\nimport re\\nimport pickle\\ntagger = pickle.load(open(\"treebank_brill_aubt.pickle\"))\\n\\nfrom nltk import bigrams\\n\\nfreq_word = {}\\nfor keyword in fq.keys()[:10]:\\n    line_num = get_line_num_by_key(keyword)\\n    fdist = nltk.FreqDist()\\n    for num in line_num:\\n        text = title_list[num]\\n        text = re.sub(\\'[,.!;()?:/]\\', \\' \\', text)\\n        text = text.split(\" \")\\n        text = tagger.tag(text)\\n        text = bigrams(text)\\n        \\n        for (word1,tag1),(word2,tag2) in text:\\n            if (tag1 in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"] or tag2 in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"]) and (word1 != \"\") and (word2 != \"\"):\\n                fdist.inc(word1.lower()+ \" \" + word2.lower())\\n    key_value = []\\n    for key in fdist.keys()[:200]:\\n        key_value.append((key,fdist[key]))\\n    freq_word[keyword] = key_value\\n'"
       ]
      }
     ],
     "prompt_number": 231
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 4. Build the new_dict dictionary that contains the tf/idf/keyword_coverage information for a given (keyword,word) pair ***\n",
      "(keyword,word): keyword and a word\n",
      "new_dict[(keyword,word)] ==> [tf, appear times in other keyword, idf]\n",
      "tf: how many times the word has appeared in the keyword\n",
      "appear times in other keyword: how many other keywords that also contain the word\n",
      "idf: how many times the word has also appeared in other keywords\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_dict = {}\n",
      "\n",
      "for keyword1 in freq_word.keys():\n",
      "    for (word1,count1) in freq_word[keyword1]:\n",
      "        appear_frequency = 0  # the word total appear times in other keywords\n",
      "        keyword_coverage = 0 # the word appear in how many other keywords\n",
      "        for keyword2 in freq_word.keys():\n",
      "            if keyword1 != keyword2:\n",
      "                for (word2,count2) in freq_word[keyword2]:\n",
      "                    if word1 == word2:\n",
      "                        appear_frequency+=count2\n",
      "                        keyword_coverage+=1\n",
      "        new_dict[(keyword1,word1)] = (count1,keyword_coverage, appear_frequency)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 5. Ouput the TFIDF table to file ***\n",
      "Each line contains [keyword, word, tf/idf, tf, appear times in other keyword, idf, total frequency of keywords]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "from __future__ import division\n",
      "f = open(\"tfidf\",\"w\")\n",
      "\n",
      "for keyword1 in fq.keys()[:200]:\n",
      "    summary = []\n",
      "    for (keyword2,word) in new_dict.keys():\n",
      "        if keyword1 == keyword2 and word[0] != '\"':\n",
      "            f.write(keyword2 + \"\\t\" + str(word) + \"\\t\" + str(new_dict[(keyword2,word)][0] / (new_dict[(keyword2,word)][2]+1)) + \"\\t\" + str(new_dict[(keyword2,word)][0])+ \"\\t\" + str(new_dict[(keyword2,word)][1]) + \"\\t\" + str(new_dict[(keyword2,word)][2]) + \"\\t\" +str(fq[keyword2])+ \"\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 6. Evaluation: Load the tfidf table to build up score table ***\n",
      "variable: load only the entries that td/idf score over __ score\n",
      "variable: specify which tfidf table want to load\n",
      "\n",
      "score_table is a word based dictionary that give a word as key return a list of keywords that has tfidf over __ score with the word\n",
      "\n",
      "ex. score_table[\"class\"] ==> [\"java\",\"c#\",\"c++\",...]\n",
      "\n",
      "means the word \"class\" has strong relationship (tfidf > __) with following keywords: java, c#, c++\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score_file = open(\"100KContent_Top50Key_Top300Word\",\"r\")\n",
      "\n",
      "score_table = {}\n",
      "\n",
      "for line in score_file:\n",
      "    line = line.strip(\"\\n\")\n",
      "    line = line.split(\"\\t\")\n",
      "    if float(line[2]) > 0.8: \n",
      "        if line[1] not in score_table:\n",
      "            score_table[line[1]] = [line[0]]\n",
      "        else:\n",
      "            score_table[line[1]].append(line[0])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 174,
       "text": [
        "'A B!C?'"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 7. Evaluation: output the prediction keywords and compare with the correct keywords ***\n",
      "variable: # of lines to predict\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Unigram\n",
      "prediction_table = []\n",
      "for i in range(len(title_list)):\n",
      "    text = data_cleaner(question_list[i])\n",
      "    key_word = {}\n",
      "    prediction = []\n",
      "    for word in text:\n",
      "        if word in score_table:\n",
      "            for j in range(len(score_table[word])):\n",
      "                if score_table[word][j] not in key_word:\n",
      "                    key_word[score_table[word][j]] = 1\n",
      "                else:\n",
      "                    key_word[score_table[word][j]] += 1\n",
      "    for key in key_word.keys():\n",
      "        if key_word[key] > 5:\n",
      "            prediction.append(key)\n",
      "    prediction_table.append(prediction)\n",
      "\n",
      "for i in range(100):\n",
      "    print \"line:\", i\n",
      "    print prediction_table[i]\n",
      "    print keyword_list[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 8. Evaluation tool: function accuracy_query(keyword) ***\n",
      "input: a keyword\n",
      "return: print the precision information about the keyword\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "def accuracy_query(keyword):\n",
      "    correct_guess = 0\n",
      "    total_key = 0\n",
      "    total_guess = 0\n",
      "    for i in range(100):\n",
      "        for guess in prediction_table[i]:\n",
      "            if guess == keyword:\n",
      "                total_guess +=1\n",
      "                if guess in keyword_list[i]:\n",
      "                    correct_guess +=1\n",
      "        for key in keyword_list[i].split(\" \"):\n",
      "            if key == keyword:\n",
      "                total_key +=1\n",
      "    print \"Total key is:\", total_key\n",
      "    print \"Total guess is:\", total_guess\n",
      "    print \"Correct guess is:\", correct_guess\n",
      "    print \"Recall is:\", correct_guess/total_key\n",
      "    print \"Accuracy is:\", correct_guess/total_guess\n",
      "    print \"Recall is:\", 2*(correct_guess/total_key)*(correct_guess/total_guess)/(correct_guess/total_key+correct_guess/total_guess)\n",
      "    \n",
      "accuracy_query(\"r\")\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}