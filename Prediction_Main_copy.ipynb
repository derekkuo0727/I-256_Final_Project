{
 "metadata": {
  "name": "Prediction_Main"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** Tool function: get_line_num_by_key(key) ***\n",
      "Input: a keyword\n",
      "Output: a list of line numbers that each of the line contains the keyword."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_line_num_by_key(key):\n",
      "    line_num = []\n",
      "    for i in range(len(keyword_list)):\n",
      "        if key in keyword_list[i].split(\" \"):\n",
      "            line_num.append(i)\n",
      "    return line_num"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** Tool function: data_cleaner(raw_text) ***\n",
      "Input: a raw text directly extracted from question_lists or title_lists\n",
      "Ouput: a list of words (ready to use) which formats have been removed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def data_cleaner(raw_text):\n",
      "    text = re.sub(\"<p>|</p>|<pre>|<code>|</pre>|</code>\", '', raw_text)\n",
      "    text = re.sub(\"\\n|[,!;?:/']\", ' ', text)\n",
      "    text = text.split(\" \")\n",
      "    li = []\n",
      "    for w in text:\n",
      "        w = w.lower()\n",
      "        if w != \"\":\n",
      "            if w[-1] == \".\":\n",
      "                w = w[:-1]\n",
      "            li.append(w)\n",
      "    return li\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** Tool function: code_extractor(raw_text) ***\n",
      "Input: a raw text directly extracted from question_lists or title_lists\n",
      "Output: a list of code sections "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def code_extractor(raw_text):\n",
      "    m = re.findall('<pre><code>(.+?)</code></pre>', raw_text, re.S)\n",
      "    return m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 0. Create a small train set (small_train.csv) from train.csv ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "input_file = open(\"train.csv\",'r')\n",
      "output_file = open(\"small_train.csv\",\"w\")\n",
      "reader = csv.reader( input_file )\n",
      "\n",
      "i = 0\n",
      "\n",
      "for line in reader:\n",
      "    a = csv.writer(output_file, delimiter=',')\n",
      "    a.writerow(line)\n",
      "    i += 1\n",
      "    if i > 1000005:\n",
      "        break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 0.1 Variable Definition ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TRAINING_LINE_NUMBER = 10000\n",
      "TOP_KEYWORDS = 20\n",
      "TOP_WORDS = 200"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 1. Load small_train.csv into title, question, keyword list ***\n",
      "variable: ___ of lines to load"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import nltk\n",
      "\n",
      "skip_first_line = True\n",
      "\n",
      "input_file = open(\"small_train.csv\",'r')\n",
      "reader = csv.reader( input_file )\n",
      "if skip_first_line:\n",
      "    reader.next()\n",
      "\n",
      "#id_list = []\n",
      "title_list = []\n",
      "question_list = []\n",
      "keyword_list = []\n",
      "\n",
      "i = 0\n",
      "\n",
      "for line in reader:\n",
      "#    id_list.append(line[0])\n",
      "    title_list.append(line[1])\n",
      "    question_list.append(line[2])\n",
      "    keyword_list.append(line[3])\n",
      "    i+=1\n",
      "    if i == TRAINING_LINE_NUMBER:\n",
      "        break\n",
      "# Now you can just call the function:\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 2. Build-up freqency table to find the most frequent keywords ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fq = nltk.FreqDist([keyword for keywords in keyword_list for keyword in keywords.split(\" \")])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 2.1 Checking_point: print the top x keywords and their frquency ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(TOP_KEYWORDS):\n",
      "    key = fq.keys()[i]\n",
      "    print key, fq[key]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "c# 778\n",
        "java 703\n",
        "php 701\n",
        "javascript 624\n",
        "android 518\n",
        "jquery 504\n",
        "c++ 333\n",
        "asp.net 309\n",
        ".net 302\n",
        "iphone 300\n",
        "python 300\n",
        "html 280\n",
        "mysql 278\n",
        "sql 256\n",
        "ios 242\n",
        "css 226\n",
        "linux 208\n",
        "ruby-on-rails 207\n",
        "objective-c 204\n",
        "c 184\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 3. Build the freq_word[keyword] dictionary (unigram version) ***\n",
      "Variable: top __ keyword\n",
      "Variable: top __ words in a keyword\n",
      "\n",
      "keyword: one of the top x keywords \n",
      "freq_word[keyword]: return a list of (word, word_count) tuples\n",
      "ex. freq_word['java'] ==> [('jsp',200),('js',100),...]\n",
      "    which means 'jsp' has appeared 200 times in the questions that contain keyword 'java' "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#unigram\n",
      "import re\n",
      "\n",
      "import pickle\n",
      "tagger = pickle.load(open(\"treebank_brill_aubt.pickle\"))\n",
      "\n",
      "from nltk.corpus import stopwords \n",
      "\n",
      "freq_word = {}\n",
      "for keyword in fq.keys()[:TOP_KEYWORDS]:\n",
      "    line_num = get_line_num_by_key(keyword)\n",
      "    target_words = []\n",
      "    for num in line_num:\n",
      "        text = data_cleaner(question_list[num])\n",
      "        text = tagger.tag(text)\n",
      "        for (word,tag) in text:\n",
      "            if (not word in stopwords.words('english'))and tag in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"] and word not in [\"\",\"=\",\"{\",\"}\",\"(\",\")\",\"+\",\"==\"]:\n",
      "                    target_words.append(word.lower())\n",
      "    fdist = nltk.FreqDist(target_words)    \n",
      "    key_value = []\n",
      "    for key in fdist.keys()[:TOP_WORDS]:\n",
      "        key_value.append((key,fdist[key]))\n",
      "    freq_word[keyword] = key_value\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** TODO: 3.1 Build the freq_word[keyword] dictionary (bigram version) ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bigrams\n",
      "\"\"\"\n",
      "import re\n",
      "import pickle\n",
      "tagger = pickle.load(open(\"treebank_brill_aubt.pickle\"))\n",
      "\n",
      "from nltk import bigrams\n",
      "\n",
      "freq_word = {}\n",
      "for keyword in fq.keys()[:10]:\n",
      "    line_num = get_line_num_by_key(keyword)\n",
      "    fdist = nltk.FreqDist()\n",
      "    for num in line_num:\n",
      "        text = title_list[num]\n",
      "        text = re.sub('[,.!;()?:/]', ' ', text)\n",
      "        text = text.split(\" \")\n",
      "        text = tagger.tag(text)\n",
      "        text = bigrams(text)\n",
      "        \n",
      "        for (word1,tag1),(word2,tag2) in text:\n",
      "            if (tag1 in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"] or tag2 in [\"JJ\",\"NN\", \"NNP\", \"NNS\",\"-None-\"]) and (word1 != \"\") and (word2 != \"\"):\n",
      "                fdist.inc(word1.lower()+ \" \" + word2.lower())\n",
      "    key_value = []\n",
      "    for key in fdist.keys()[:200]:\n",
      "        key_value.append((key,fdist[key]))\n",
      "    freq_word[keyword] = key_value\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 4. Build the new_dict dictionary that contains the tf/idf/keyword_coverage information for a given (keyword,word) pair ***\n",
      "(keyword,word): keyword and a word\n",
      "new_dict[(keyword,word)] ==> [tf, appear times in other keyword, idf]\n",
      "tf: how many times the word has appeared in the keyword\n",
      "appear times in other keyword: how many other keywords that also contain the word\n",
      "idf: how many times the word has also appeared in other keywords\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_dict = {}\n",
      "\n",
      "for keyword1 in freq_word.keys():\n",
      "    for (word1,count1) in freq_word[keyword1]:\n",
      "        appear_frequency = 0  # the word total appear times in other keywords\n",
      "        keyword_coverage = 0 # the word appear in how many other keywords\n",
      "        for keyword2 in freq_word.keys():\n",
      "            if keyword1 != keyword2:\n",
      "                for (word2,count2) in freq_word[keyword2]:\n",
      "                    if word1 == word2:\n",
      "                        appear_frequency+=count2\n",
      "                        keyword_coverage+=1\n",
      "        new_dict[(keyword1,word1)] = (count1,keyword_coverage, appear_frequency)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 5. Ouput the TFIDF table to file ***\n",
      "Each line contains [keyword, word, tf/idf, tf, appear times in other keyword, idf, total frequency of keywords]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "from __future__ import division\n",
      "f = open(\"tfidf\",\"w\")\n",
      "\n",
      "for keyword1 in fq.keys()[:TOP_KEYWORDS]:\n",
      "    summary = []\n",
      "    for (keyword2,word) in new_dict.keys():\n",
      "        if keyword1 == keyword2 and word[0] != '\"':\n",
      "            f.write(keyword2 + \"\\t\" + str(word) + \"\\t\" + str(new_dict[(keyword2,word)][0] / (new_dict[(keyword2,word)][2]+1)) + \"\\t\" + str(new_dict[(keyword2,word)][0])+ \"\\t\" + str(new_dict[(keyword2,word)][1]) + \"\\t\" + str(new_dict[(keyword2,word)][2]) + \"\\t\" +str(fq[keyword2])+ \"\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 6.0 Evaluation Variable Definition ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TFIDF_Threshold = 10\n",
      "NUMBER_OF_MATCHES = 2\n",
      "TESTING_LINES = 100,200"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 6. Evaluation: Load the tfidf table to build up score table ***\n",
      "variable: load only the entries that td/idf score over __ score\n",
      "variable: specify which tfidf table want to load\n",
      "\n",
      "score_table is a word based dictionary that give a word as key return a list of keywords that has tfidf over __ score with the word\n",
      "\n",
      "ex. score_table[\"class\"] ==> [\"java\",\"c#\",\"c++\",...]\n",
      "\n",
      "means the word \"class\" has strong relationship (tfidf > __) with following keywords: java, c#, c++\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score_file = open(\"100KContent_Top50Key_Top300Word\",\"r\")\n",
      "\n",
      "score_table = {}\n",
      "\n",
      "for line in score_file:\n",
      "    line = line.strip(\"\\n\")\n",
      "    line = line.split(\"\\t\")\n",
      "    if float(line[2]) > TFIDF_Threshold: \n",
      "        if line[1] not in score_table:\n",
      "            score_table[line[1]] = [line[0]]\n",
      "        else:\n",
      "            score_table[line[1]].append(line[0])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 7. Evaluation: output the prediction keywords and compare with the correct keywords ***\n",
      "variable: # of lines to predict\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Unigram\n",
      "prediction_table = []\n",
      "for i in range(len(title_list)):\n",
      "    text = data_cleaner(question_list[i])\n",
      "    key_word = {}\n",
      "    prediction = []\n",
      "    for word in text:\n",
      "        if word in score_table:\n",
      "            for j in range(len(score_table[word])):\n",
      "                if score_table[word][j] not in key_word:\n",
      "                    key_word[score_table[word][j]] = 1\n",
      "                else:\n",
      "                    key_word[score_table[word][j]] += 1\n",
      "    for key in key_word.keys():\n",
      "        if key_word[key] > NUMBER_OF_MATCHES:\n",
      "            prediction.append(key)\n",
      "    prediction_table.append(prediction)\n",
      "\n",
      "for i in range(TESTING_LINES):\n",
      "    print \"line:\", i\n",
      "    print prediction_table[i]\n",
      "    print keyword_list[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 8. Evaluation tool: function accuracy_query(keyword) ***\n",
      "input: a keyword\n",
      "return: print the precision information about the keyword\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "def accuracy_query(keyword):\n",
      "    correct_guess = 0\n",
      "    total_key = 0\n",
      "    total_guess = 0\n",
      "    for i in range(TESTING_LINES):\n",
      "        for guess in prediction_table[i]:\n",
      "            if guess == keyword:\n",
      "                total_guess +=1\n",
      "                if guess in keyword_list[i]:\n",
      "                    correct_guess +=1\n",
      "        for key in keyword_list[i].split(\" \"):\n",
      "            if key == keyword:\n",
      "                total_key +=1\n",
      "    print \"Total key is:\", total_key\n",
      "    print \"Total guess is:\", total_guess\n",
      "    print \"Correct guess is:\", correct_guess\n",
      "    print \"Recall is:\", correct_guess/total_key\n",
      "    print \"Accuracy is:\", correct_guess/total_guess\n",
      "    print \"Recall is:\", 2*(correct_guess/total_key)*(correct_guess/total_guess)/(correct_guess/total_key+correct_guess/total_guess)\n",
      "    \n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "*** 9. Test specific keyword accuracy ***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy_query(\"r\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}